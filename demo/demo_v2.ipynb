{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30de281b-5aee-4e21-a402-d9b7edbd65ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db2e5f2c-0b5a-4c47-8280-4ff3c150c0e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from hython.preprocess import reshape, apply_normalization\n",
    "from hython.datasets.datasets import LSTMDataset\n",
    "from hython.train_val import train_val\n",
    "from hython.sampler import RegularIntervalSampler, SpaceSampler\n",
    "from hython.metrics import mse_metric\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Dataset\n",
    "\n",
    "from hython.utils import missing_location_idx, reconstruct_from_missing, load\n",
    "from hython.models.lstm import CustomLSTM\n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt\n",
    "from hython.viz import plot_sampler\n",
    "from hython.utils import predict, prepare_for_plotting\n",
    "from hython.viz import map_bias, map_pbias, map_pearson, map_at_timesteps, ts_compare, plot_sampler\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a78cf5-bd72-4a3d-bd18-ce49d0e8fdee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58ea7b19-4cdf-4345-9481-ff178e1d0440",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_names = [\"precip\", \"pet\", \"temp\"]\n",
    "static_names = [ 'M', 'thetaS', 'RootingDepth', 'Kext', 'Sl', 'Swood', 'TT', 'KsatHorFrac'] \n",
    "target_names = [ \"vwc\",\"actevap\" ] # \"q_river\"]\n",
    "\n",
    "fn_forcings =  \"forcings.nc\"  # 'inmaps_eobs_eobsd_makkink_86400_2015_2019.nc' \n",
    "fn_params = \"staticmaps.nc\"\n",
    "fn_targets = \"output.nc\"\n",
    "\n",
    "\n",
    "# DEMO \n",
    "\n",
    "wflow_model = \"datademo\" #\"adg1km_eobs\" #\"datademo\" # \"alps1km_eobs\" # \"alps1km_cerra\", \n",
    "\n",
    "wd = Path(\"../data\") / wflow_model\n",
    "\n",
    "fp_dynamic_forcings = wd / fn_forcings \n",
    "fp_wflow_static_params = wd / fn_params\n",
    "fp_target = wd / fn_targets\n",
    "\n",
    "forcings = xr.open_dataset(fp_dynamic_forcings)\n",
    "params = xr.open_dataset(fp_wflow_static_params)\n",
    "targets = xr.open_dataset(fp_target).isel(lat=slice(None, None, -1))\n",
    "\n",
    "\n",
    "# EURAC FILE SYSTEM\n",
    "\n",
    "wflow_model = \"alps1km_eobs\" # \"adg1km_eobs\"\n",
    "\n",
    "wd = Path(\"/mnt/CEPH_PROJECTS/InterTwin/Wflow/models\") / wflow_model\n",
    "\n",
    "input_dir_path = Path('/mnt/CEPH_PROJECTS/InterTwin/Wflow/models') / wflow_model\n",
    "output_dir_path = Path('/mnt/CEPH_PROJECTS/InterTwin/surrogate/')\n",
    "model_weigths_path = output_dir_path / \"model_weights\"\n",
    "surrogate_input_path = Path(\"/mnt/CEPH_PROJECTS/InterTwin/hydrologic_data/surrogate_training\")\n",
    "\n",
    "forcings = xr.open_dataset(input_dir_path / fn_forcings , chunks= {\"time\":100})\n",
    "params = xr.open_dataset(input_dir_path / fn_params ,  chunks= {\"time\":100}).sel(layer=1)\n",
    "targets = xr.open_dataset(input_dir_path / \"run_default\" / fn_targets, chunks= {\"time\":100}).sel(layer=1).isel(lat=slice(None, None, -1))\n",
    "\n",
    "\n",
    "(surrogate_input_path / f\"{wflow_model}.npz\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dc89091-8031-4968-8213-1600f65afe59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select forcings, wflow parameters and targets\n",
    "forcings = forcings[dynamic_names]\n",
    "params = params[static_names]\n",
    "targets = targets[target_names] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f520f3ec-054f-4281-abca-24cb2f70529f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<xarray.Dataset>\n",
       " Dimensions:  (time: 90, lat: 689, lon: 1177)\n",
       " Coordinates:\n",
       "   * time     (time) datetime64[ns] 2015-01-01 2015-01-02 ... 2015-03-31\n",
       "   * lon      (lon) float64 5.079 5.088 5.098 5.107 ... 15.83 15.84 15.85 15.86\n",
       "   * lat      (lat) float64 50.03 50.02 50.01 50.0 ... 43.75 43.74 43.73 43.72\n",
       " Data variables:\n",
       "     precip   (time, lat, lon) float32 dask.array<chunksize=(90, 689, 1177), meta=np.ndarray>\n",
       "     pet      (time, lat, lon) float32 dask.array<chunksize=(90, 689, 1177), meta=np.ndarray>\n",
       "     temp     (time, lat, lon) float32 dask.array<chunksize=(90, 689, 1177), meta=np.ndarray>\n",
       " Attributes:\n",
       "     standard_name:  thickness_of_rainfall_amount\n",
       "     long_name:      rainfall\n",
       "     units:          mm\n",
       "     cell_methods:   time: mean\n",
       "     category:       meteo\n",
       "     version:        27\n",
       "     _FillValue:     nan\n",
       "     unit:           mm\n",
       "     precip_fn:      eobs,\n",
       " <xarray.Dataset>\n",
       " Dimensions:       (lat: 689, lon: 1177)\n",
       " Coordinates:\n",
       "   * lat           (lat) float64 50.03 50.02 50.01 50.0 ... 43.74 43.73 43.72\n",
       "   * lon           (lon) float64 5.079 5.088 5.098 5.107 ... 15.84 15.85 15.86\n",
       "     layer         int64 1\n",
       "     spatial_ref   int64 ...\n",
       " Data variables:\n",
       "     M             (lat, lon) float32 dask.array<chunksize=(689, 1177), meta=np.ndarray>\n",
       "     thetaS        (lat, lon) float32 dask.array<chunksize=(689, 1177), meta=np.ndarray>\n",
       "     RootingDepth  (lat, lon) float64 dask.array<chunksize=(689, 1177), meta=np.ndarray>\n",
       "     Kext          (lat, lon) float64 dask.array<chunksize=(689, 1177), meta=np.ndarray>\n",
       "     Sl            (lat, lon) float64 dask.array<chunksize=(689, 1177), meta=np.ndarray>\n",
       "     Swood         (lat, lon) float64 dask.array<chunksize=(689, 1177), meta=np.ndarray>\n",
       "     TT            (lat, lon) float32 dask.array<chunksize=(689, 1177), meta=np.ndarray>\n",
       "     KsatHorFrac   (lat, lon) float32 dask.array<chunksize=(689, 1177), meta=np.ndarray>,\n",
       " <xarray.Dataset>\n",
       " Dimensions:  (time: 1825, lat: 689, lon: 1177)\n",
       " Coordinates:\n",
       "   * lon      (lon) float64 5.079 5.088 5.098 5.107 ... 15.83 15.84 15.85 15.86\n",
       "   * lat      (lat) float64 50.03 50.02 50.01 50.0 ... 43.75 43.74 43.73 43.72\n",
       "     layer    float64 1.0\n",
       "   * time     (time) datetime64[ns] 2015-01-02 2015-01-03 ... 2019-12-31\n",
       " Data variables:\n",
       "     vwc      (time, lat, lon) float32 dask.array<chunksize=(100, 344, 589), meta=np.ndarray>\n",
       "     actevap  (time, lat, lon) float32 dask.array<chunksize=(100, 689, 1177), meta=np.ndarray>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forcings, params, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d42ad07-01b9-4649-9f6b-bff75dbf84b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    forcings = forcings.rename({\"latitude\":\"lat\", \"longitude\":\"lon\"})\n",
    "    params = params.rename({\"latitude\":\"lat\", \"longitude\":\"lon\"})\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34939cd-07a7-499d-bd10-6dd60f1b0236",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac8843a5-1a82-4f93-bd8b-87df03b4adcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training \n",
    "\n",
    "spatial_batch_size = 128\n",
    "temporal_sampling_size = 150 \n",
    "seq_length = 90 # days\n",
    "\n",
    "# model \n",
    "\n",
    "hidden_size = 32\n",
    "\n",
    "model_params={\n",
    "    \"input_size\": 3, #number of dynamic predictors - user_input\n",
    "    \"hidden_size\": hidden_size, # user_input\n",
    "    \"output_size\": len(target_names), # number_target - user_input\n",
    "    \"number_static_predictors\": len(static_names), #number of static parameters - user_input \n",
    "\n",
    "}\n",
    "\n",
    "## The used device for training\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909b2f6-5e1d-474c-a0ed-f7287e5fc408",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424198cd-55f4-47cb-a92f-bf23ce77ebb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remove_lakes = True\n",
    "\n",
    "if remove_lakes:\n",
    "    mask_lakes = (targets.mean(dim = \"time\")[\"actevap\"] == 0).astype(np.bool_)\n",
    "    targets = targets.where(~mask_lakes, np.nan)\n",
    "    forcings = forcings.where(~mask_lakes, np.nan)\n",
    "    params = params.where(~mask_lakes, np.nan)\n",
    "\n",
    "\n",
    "timeslice = slice(\"2014-01-01\",\"2020-12-31\")\n",
    "\n",
    "if timeslice:\n",
    "    forcings = forcings.sel(time=timeslice)\n",
    "    targets = targets.sel(time=timeslice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f2004a-d784-4370-9cb3-ff5903976f6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT IF NOT LOADING PREPROCESSED INPUTS\n",
    "\n",
    "#reshape for training\n",
    "\n",
    "# Xd, Xs, Y  = reshape(\n",
    "#                    forcings, \n",
    "#                    params, \n",
    "#                    targets\n",
    "#                    )\n",
    "\n",
    "#Define the 2D missing values mask. Sampling \n",
    "\n",
    "# missing_mask = np.isnan(params.M).values\n",
    "\n",
    "# UNCOMMENT TO SAVE\n",
    "# np.savez_compressed( surrogate_input_path / f\"{wflow_model}\", Xd=Xd, Xs=Xs, Y=Y, missing_mask = missing_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f72fe449-0b84-46d9-a1ef-a753f0f5053f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((810953, 1461, 3), (810953, 8), (810953, 1461, 2), (689, 1177))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # loading preprocessed data\n",
    "Xd, Xs, Y, missing_mask = load(surrogate_input_path, wflow_model, files = [\"Xd\", \"Xs\", \"Y\", \"missing_mask\"])\n",
    "Xd.shape, Xs.shape, Y.shape, missing_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7cda342-cc18-4b45-884c-3ceb9b4780f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the spatial samplers for both training and validation sets. Remeber the subsets should not overlap.\n",
    "\n",
    "intervals = (5, 5) # every n km\n",
    "train_origin = (0, 0)\n",
    "val_origin = (3, 3)\n",
    "\n",
    "spatial_train_sampler = RegularIntervalSampler(intervals = intervals, origin = train_origin)\n",
    "spatial_val_sampler = RegularIntervalSampler(intervals = intervals, origin = val_origin) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53032777-b68f-4ee2-87ed-006bdbd7f1df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the samplers to the 2D domain. The samplers return the cell indices that can be used later in training and validation to sample the whole domain.\n",
    "\n",
    "data2d  = forcings.to_dataarray().transpose(\"lat\",\"lon\", \"time\", \"variable\")\n",
    "\n",
    "sampler_train_meta = spatial_train_sampler.sampling_idx(data2d, missing_mask)\n",
    "sampler_val_meta = spatial_val_sampler.sampling_idx(data2d, missing_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4520ea49-a25a-475f-a683-0a77fd535dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SamplerResult(\n",
       " - id_grid_2d: (689, 1177) \n",
       " - idx_sampled_1d: (32568,) \n",
       " - idx_sampled_1d_nomissing: (14889,)) \n",
       " - idx_missing_1d: (438870,) \n",
       " - sampled_grid_dims: (138, 236, 0, 3) \n",
       " - xr_coords: Coordinates:\n",
       "  * time     (time) datetime64[ns] \n",
       "  * lon      (lon) float64 5.079 5.125 5.171 5.217 ... 15.71 15.76 15.8 15.85\n",
       "  * lat      (lat) float64 50.03 49.98 49.94 49.89 ... 43.89 43.84 43.79 43.75\n",
       "    layer    float64 1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler_train_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59a40c5e-a7c0-4c34-8b7e-b9859748beee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check location of training and validation sets\n",
    "#plot_sampler(params.Kext, sampler_train_meta, sampler_val_meta, figsize= (10, 10 ), markersize = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "816ea66a-5408-459e-9a07-8bc1a874323c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.937524, 1.823418, 8.389286], dtype=float32),\n",
       " array([1.59851750e+02, 4.73244885e-01, 2.67128072e+02, 6.66277746e-01,\n",
       "        8.10883391e-02, 1.66977270e-01, 0.00000000e+00, 1.00000000e+02]),\n",
       " array([0.2900982, 1.1470997], dtype=float32),\n",
       " array([6.5156603, 1.3547534, 8.364874 ], dtype=float32),\n",
       " array([2.99913272e+02, 3.71567510e-02, 1.02389902e+02, 6.94902583e-02,\n",
       "        3.09562090e-02, 1.69922776e-01, 1.00000000e+00, 1.00000000e+00]),\n",
       " array([0.06689665, 0.9305376 ], dtype=float32))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Normalizing v1\n",
    "# # training\n",
    "#Xd[sampler_train_meta.idx_sampled_1d_nomissing], d_m, d_std = apply_normalization(Xd[sampler_train_meta.idx_sampled_1d_nomissing], type = \"spacetime\", how ='standard')\n",
    "#Xs[sampler_train_meta.idx_sampled_1d_nomissing], s_m, s_std = apply_normalization(Xs[sampler_train_meta.idx_sampled_1d_nomissing], type = \"space\", how ='standard')\n",
    "#Y[sampler_train_meta.idx_sampled_1d_nomissing], y_m, y_std = apply_normalization(Y[sampler_train_meta.idx_sampled_1d_nomissing], type = \"spacetime\", how ='standard')\n",
    "# # validation \n",
    "# Xd[sampler_val_meta.idx_sampled_1d_nomissing] = apply_normalization(Xd[sampler_val_meta.idx_sampled_1d_nomissing], type = \"spacetime\", how ='standard', m1 = d_m, m2 = d_std)\n",
    "# Xs[sampler_val_meta.idx_sampled_1d_nomissing] = apply_normalization(Xs[sampler_val_meta.idx_sampled_1d_nomissing], type = \"space\", how ='standard', m1 = s_m, m2 = s_std)\n",
    "# Y[sampler_val_meta.idx_sampled_1d_nomissing] = apply_normalization(Y[sampler_val_meta.idx_sampled_1d_nomissing], type = \"spacetime\", how ='standard', m1 = y_m, m2 = y_std)\n",
    "\n",
    "\n",
    "# # Normalizing V2\n",
    "# # training\n",
    "_, d_m, d_std = apply_normalization(Xd[sampler_train_meta.idx_sampled_1d_nomissing], type = \"spacetime\", how ='standard')\n",
    "_, s_m, s_std = apply_normalization(Xs[sampler_train_meta.idx_sampled_1d_nomissing], type = \"space\", how ='standard')\n",
    "_, y_m, y_std = apply_normalization(Y[sampler_train_meta.idx_sampled_1d_nomissing], type = \"spacetime\", how ='standard')\n",
    "\n",
    "d_m, s_m, y_m, d_std, s_std, y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e34e05-3eb9-4f75-aab8-b33e62dd5d99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xd = apply_normalization(Xd, type=\"spacetime\", how=\"standard\", m1 = d_m, m2 = d_std)\n",
    "Xs = apply_normalization(Xs, type=\"space\", how=\"standard\",  m1 = s_m, m2 = s_std)\n",
    "Y = apply_normalization(Y, type=\"spacetime\",how=\"standard\", m1 = y_m, m2 = y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee13790d-eadd-4ef9-ae65-47df647016d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.isnan(Xd[sampler_val_meta.idx_sampled_1d_nomissing]).any(), np.isnan(Xs[sampler_val_meta.idx_sampled_1d_nomissing]).any(), np.isnan(Y[sampler_val_meta.idx_sampled_1d_nomissing]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa6bb3-2146-4008-914a-d7c8b70e4f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.isnan(Xd[sampler_train_meta.idx_sampled_1d_nomissing]).any(), np.isnan(Xs[sampler_train_meta.idx_sampled_1d_nomissing]).any(), np.isnan(Y[sampler_train_meta.idx_sampled_1d_nomissing]).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a747bc5a-fe58-4c63-8945-55e660dd9208",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare Model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c76f83-b3f8-4ec6-9b50-03a3db913e00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xs = torch.Tensor(Xs)\n",
    "Xd = torch.Tensor(Xd)\n",
    "Y = torch.Tensor(Y)\n",
    "\n",
    "Xs.shape, Xd.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb0b4b1-b5f8-4faa-b77c-c71732edb76a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init datasets\n",
    "dataset = LSTMDataset(Xd, Y, Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a379cef-7408-45f8-b306-484e932cd2b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sampler = SpaceSampler(dataset, num_samples=100, sampling_indices = sampler_train_meta.idx_sampled_1d_nomissing.tolist())\n",
    "valid_sampler = SpaceSampler(dataset, num_samples=100, sampling_indices = sampler_val_meta.idx_sampled_1d_nomissing.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7823e88-a612-45be-a8a3-3ba316552dc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=spatial_batch_size, shuffle=False, sampler = train_sampler) # implement shuffling in the sampler!\n",
    "val_loader = DataLoader(dataset, batch_size=spatial_batch_size, shuffle=False, sampler = valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956a6670-55cf-4c23-88fe-685b4343bc2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for x,y,s in train_loader:\n",
    "#     print(x.shape, y.shape, s.shape)\n",
    "#     #plt.plot(x[...,0].numpy())\n",
    "#     print(i)\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaedbed-af8b-44da-a677-a56bed8b8706",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b046cecf-ee3c-4b85-b68b-bfd62089e87d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CustomLSTM(model_params)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0751f35d-23e0-4dcf-b67b-b034964f2a87",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train/valid settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f4b4d9-489d-400f-99a3-c079cfe8a715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path2models= \"./checkpoints\" \n",
    "if not os.path.exists(path2models):\n",
    "    os.mkdir(path2models)\n",
    "    \n",
    "    \n",
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "## Set the metric function - here using the same loss function \n",
    "metric_fn = mse_metric\n",
    "\n",
    "## Set the learning rate scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=10)\n",
    "\n",
    "epochs = 60\n",
    "\n",
    "\n",
    "## Set the training parameters\n",
    "params_train={\n",
    "    \"num_epochs\": epochs,\n",
    "    \"temporal_sampling_idx_change_with_epoch\": True,\n",
    "    \"temporal_sampling_size\": temporal_sampling_size,\n",
    "    \"seq_length\": seq_length,\n",
    "    \"ts_range\": Y.shape[1],\n",
    "    \"optimizer\": opt,\n",
    "    \"loss_func\": loss_fn,\n",
    "    \"metric_func\": metric_fn,\n",
    "    \"train_dl\": train_loader, \n",
    "    \"val_dl\": val_loader,\n",
    "    \"lr_scheduler\": lr_scheduler,\n",
    "    \"path2weights\": f\"{path2models}/weights.pt\",\n",
    "    \"device\":device,\n",
    "    \"target_names\": target_names\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aae90c-39ff-42ef-bbaa-77e04da01f40",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run Train/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74736824-bccb-4242-859f-c5984889bc36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, sm_loss_history, sm_metric_history = train_val(model, params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5791b45c-d303-4979-98bf-59f2b2596bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# Extract the loss values\n",
    "train_loss = sm_metric_history['train_vwc']\n",
    "val_loss = sm_metric_history['val_vwc']\n",
    "\n",
    "# Create a list of epochs for the x-axis (e.g., [1, 2, 3, ..., 100])\n",
    "lepochs = list(range(1,params_train[\"num_epochs\"] + 1))\n",
    "\n",
    "# Create the train and validation loss plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lepochs, train_loss, marker='o', linestyle='-', color='b', label='Training Loss')\n",
    "plt.plot(lepochs, val_loss, marker='o', linestyle='-', color='r', label='Validation Loss')\n",
    "plt.title('Validation Loss - SM')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5467c3-9a3f-4bb5-8a9c-027c234e3fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# Extract the loss values\n",
    "train_loss = sm_metric_history['train_actevap']\n",
    "val_loss = sm_metric_history['val_actevap']\n",
    "\n",
    "# Create a list of epochs for the x-axis (e.g., [1, 2, 3, ..., 100])\n",
    "lepochs = list(range(1,params_train[\"num_epochs\"] + 1))\n",
    "\n",
    "# Create the train and validation loss plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lepochs, train_loss, marker='o', linestyle='-', color='b', label='Training Loss')\n",
    "plt.plot(lepochs, val_loss, marker='o', linestyle='-', color='r', label='Validation Loss')\n",
    "plt.title('Validation Loss - ET')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd74d115-5c4d-4b54-acbb-326ead31e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(params_train[\"path2weights\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b659be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "##model= model.to('cuda:0')\n",
    "#model= model.to('cpu')\n",
    "#it = iter(train_loader)\n",
    "# din, static, val = next(it)\n",
    "# din.shape, static.shape, val.shape\n",
    "# plt.figure(figsize=(20,10)) \n",
    "# plt.plot(model(din, static).detach().cpu().numpy()[101,:,1], label =\"model\")\n",
    "# plt.plot(val[101,:,1], label=\"val\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c64054e-d5f3-41ad-ac31-07bbcd13af2e",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b560e-4c24-4239-8d47-ab97b1f78eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cbcb0e-f08d-41e0-a2df-f751cd935139",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = predict(Xd, Xs, model, spatial_batch_size, device=\"cpu\")\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f01a11-dec5-42b6-892d-d94771c8a238",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon, time = *forcings.to_dataarray().transpose(\"lat\",\"lon\", \"time\", \"variable\").shape[:2], Xd.shape[1]\n",
    "lat*lon ,time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f14ba65-3f29-4e74-aef7-9456efc07523",
   "metadata": {},
   "source": [
    "## SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d917cef-eb03-4209-84a2-fd56223ba1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target, y_pred = prepare_for_plotting(y_target=Y[:,:,[0]], y_pred = yhat[:,:,[0]], shape = (lat, lon, time), coords = targets[target_names].coords)\n",
    "y_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e854d-8684-43d5-815b-3688501cf8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_pbias(y_target, y_pred, figsize = (8, 8)) #, kwargs_imshow = {\"vmin\":-100, \"vmax\":100 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a26edfc-b674-4f66-b2c5-671a18c14566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_pearson(y_target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec7eac-c397-4a36-aa1a-091f60cfc33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946517c-1310-447e-ad09-11634c2530e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_compare(y_target, y_pred, lat = [46.4, 46.5, 46.3], lon = [11.4, 11.3, 11.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e9af6-7eff-4e46-8177-cf2cbff4af07",
   "metadata": {},
   "source": [
    "## ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753fd14-b393-4e1e-b2e2-b6e00e068402",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target_et, y_pred_et = prepare_for_plotting(y_target=Y[:,:,[1]], y_pred = yhat[:,:,[1]], shape = (lat, lon, time), coords = targets[target_names].coords)\n",
    "y_target_et.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e51c99f-0990-456d-b9eb-0f9f7cca1eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_pbias(y_target, y_pred, figsize = (12, 12)) #, kwargs_imshow = {\"vmin\":-100, \"vmax\":100 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b309046-9ad2-4fc8-95f5-140b930a1ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_compare(y_target_et, y_pred_et, lat = [46.4, 46.5, 46.3], lon = [11.4, 11.3, 11.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfde4b7-ca03-4dd4-9ff5-4b9070d3de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e34a36f-44b9-4854-b333-30b9f5f4489b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emulator",
   "language": "python",
   "name": "emulator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
