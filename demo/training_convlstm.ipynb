{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "913afcd2-a55e-4804-adf4-699a3f3a660a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed6a0ce1-163e-40ac-9e7e-e6d5f364bd84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4635e3f-8a34-48ac-b4f5-d871bdfcda0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import torch\n",
    "\n",
    "from hython.models.convLSTM import ConvLSTM\n",
    "from hython.datasets.datasets import get_dataset\n",
    "from hython.sampler import SamplerBuilder, CubeletsDownsampler\n",
    "from hython.trainer import HythonTrainer, RNNTrainParams, train_val\n",
    "from hython.metrics import MSEMetric\n",
    "from hython.losses import RMSELoss\n",
    "from hython.normalizer import Normalizer\n",
    "from hython.utils import write_to_zarr, read_from_zarr, set_seed\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a78cf5-bd72-4a3d-bd18-ce49d0e8fdee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3186025-caa2-429f-88da-8c9c6b23c292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "EXPERIMENT  = \"exp1\"\n",
    "\n",
    "SURROGATE_INPUT = \"https://eurac-eo.s3.amazonaws.com/INTERTWIN/SURROGATE_INPUT/adg1km_eobs_original.zarr/\"\n",
    "\n",
    "SURROGATE_MODEL_OUTPUT = f\"path/to/model/output/directory/{EXPERIMENT}.pt\"\n",
    "\n",
    "TMP_STATS = \"path/to/temporary/stats/directory\" \n",
    "\n",
    "# === FILTER ==============================================================\n",
    "\n",
    "# train/test temporal range\n",
    "train_temporal_range = slice(\"2012-01-01\",\"2018-12-31\")\n",
    "test_temporal_range = slice(\"2019-01-01\", \"2020-12-31\")\n",
    "\n",
    "# variables\n",
    "dynamic_names = [\"precip\", \"pet\", \"temp\"] \n",
    "static_names = [ \"thetaS\", \"thetaR\", \"KsatVer\", \"SoilThickness\", \"RootingDepth\", \"f\", \"Swood\", \"Sl\", \"Kext\"]\n",
    "target_names = [\"vwc\", \"actevap\"]# [\"vwc\", \"actevap\", \"snow\", \"snowwater\"] \n",
    "\n",
    "# === MASK ========================================================================================\n",
    "\n",
    "mask_names = [\"mask_missing\", \"mask_lake\"] # names depends on preprocessing application\n",
    "\n",
    "# === DATASET ========================================================================================\n",
    "\n",
    "DATASET = \"CubeletsDataset\" \n",
    "\n",
    "XSIZE,YSIZE, TSIZE = 10, 10, 360\n",
    "XOVER,YOVER,TOVER = 5, 5, 220\n",
    "\n",
    "MISSING_POLICY = 0.05 # \"any\", \"all\"\n",
    "\n",
    "# == MODEL  ========================================================================================\n",
    "\n",
    "HIDDEN_SIZE = 36 # \n",
    "DYNAMIC_INPUT_SIZE = len(dynamic_names)\n",
    "STATIC_INPUT_SIZE = len(static_names)\n",
    "KERNEL_SIZE = (3, 3) # height, width\n",
    "NUM_LSTM_LAYER = 1\n",
    "OUTPUT_SIZE = len(target_names)\n",
    "\n",
    "TARGET_WEIGHTS = {t:1/len(target_names) for t in target_names}\n",
    "\n",
    "\n",
    "# === SAMPLER/TRAINER ===================================================================================\n",
    "\n",
    "# downsampling\n",
    "DONWSAMPLING = False\n",
    "\n",
    "TEMPORAL_FRAC = [0.8, 0.8] # train, test\n",
    "SPATIAL_FRAC = [1, 1]  # train, test\n",
    "\n",
    "# gradient clipping\n",
    "gradient_clip = {\"max_norm\":1} # None\n",
    "\n",
    "SEED = 42\n",
    "EPOCHS = 20\n",
    "BATCH = 32\n",
    "\n",
    "\n",
    "assert (sum(v for v in TARGET_WEIGHTS.values()) - 1) < 0.01, \"check target weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c67bf4f-55e3-46fc-927b-72711d831f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "221b3d8f-3c17-4b4b-bd85-8cfc1c765f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === READ TRAIN ===================================================================\n",
    "Xd = (\n",
    "    read_from_zarr(url=SURROGATE_INPUT , group=\"xd\")\n",
    "    .sel(time=train_temporal_range)[dynamic_names]\n",
    ")\n",
    "Xs = read_from_zarr(url=SURROGATE_INPUT , group=\"xs\")[static_names]\n",
    "\n",
    "Y = (\n",
    "    read_from_zarr(url=SURROGATE_INPUT , group=\"y\")\n",
    "    .sel(time=train_temporal_range)[target_names]\n",
    ")\n",
    "\n",
    "SHAPE = Xd.attrs[\"shape\"]\n",
    "\n",
    "# === READ TEST ===================================================================\n",
    "\n",
    "Y_test = (\n",
    "    read_from_zarr(url=SURROGATE_INPUT , group=\"y\")\n",
    "    .sel(time=test_temporal_range)[target_names]\n",
    ")\n",
    "Xd_test = (\n",
    "    read_from_zarr(url=SURROGATE_INPUT , group=\"xd\")\n",
    "    .sel(time=test_temporal_range)[dynamic_names]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "314c3596-a997-4b68-a94e-e7b48c3267e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masks = (\n",
    "    read_from_zarr(url=SURROGATE_INPUT, group=\"mask\")\n",
    "    .mask.sel(mask_layer=mask_names)\n",
    "    .any(dim=\"mask_layer\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1f6c0de-d71a-430b-91fc-52fff2d259b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DONWSAMPLING:\n",
    "    train_downsampler = CubeletsDownsampler(\n",
    "        temporal_downsample_fraction= TEMPORAL_FRAC[0], \n",
    "        spatial_downsample_fraction= SPATIAL_FRAC[0]\n",
    "    )       \n",
    "    test_downsampler = CubeletsDownsampler(\n",
    "        temporal_downsample_fraction= TEMPORAL_FRAC[-1], \n",
    "        spatial_downsample_fraction= SPATIAL_FRAC[-1]\n",
    "    )\n",
    "else:\n",
    "    train_downsampler,test_downsampler = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "419b87d9-a610-4933-8fd1-6579aefbc99f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_dynamic = Normalizer(method = \"standardize\", type=\"spacetime\", axis_order = \"xarray_dataset\")\n",
    "                                #save_stats=  f\"{TMP_STATS}/{EXPERIMENT}_xd.nc\")\n",
    "normalizer_static = Normalizer(method = \"standardize\", type=\"space\", axis_order = \"xarray_dataset\")\n",
    "                               #save_stats=  f\"{TMP_STATS}/{EXPERIMENT}_xs.nc\")\n",
    "normalizer_target = Normalizer(method = \"standardize\", type=\"spacetime\", axis_order = \"xarray_dataset\")\n",
    "                               #save_stats=  f\"{TMP_STATS}/{EXPERIMENT}_y.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad1bf4b0-74c0-4c3b-94dd-baf352a757b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(DATASET)(Xd.chunk(\"auto\"), \n",
    "                          Y.chunk(\"auto\"),\n",
    "                          Xs.chunk(\"auto\"),\n",
    "                          mask = masks,\n",
    "                          downsampler=train_downsampler,\n",
    "                          # normalizer_dynamic = normalizer_dynamic, \n",
    "                          # normalizer_static = normalizer_static,\n",
    "                          # normalizer_target = normalizer_target,\n",
    "                          shape=Xd.precip.shape, # time, lat, lon\n",
    "                          batch_size={\"xsize\":XSIZE,\"ysize\":YSIZE,\"tsize\":TSIZE}, \n",
    "                          overlap={\"xover\":XOVER, \"yover\":YOVER, \"tover\":TOVER},\n",
    "                          missing_policy=MISSING_POLICY,\n",
    "                          fill_missing=0,\n",
    "                          persist=True, \n",
    "                          lstm_1d=False, \n",
    "                          static_to_dynamic=True\n",
    "                         )\n",
    "test_dataset = get_dataset(DATASET)(Xd_test.chunk(\"auto\"), \n",
    "                          Y_test.chunk(\"auto\"),\n",
    "                          Xs.chunk(\"auto\"),\n",
    "                          mask = masks,\n",
    "                          downsampler=test_downsampler,\n",
    "                          # normalizer_dynamic = normalizer_dynamic, \n",
    "                          # normalizer_static = normalizer_static,\n",
    "                          # normalizer_target = normalizer_target,\n",
    "                          shape=Xd_test.precip.shape, # time, lat, lon\n",
    "                          batch_size={\"xsize\":XSIZE,\"ysize\":YSIZE,\"tsize\":TSIZE}, \n",
    "                          overlap={\"xover\":XOVER, \"yover\":YOVER, \"tover\":TOVER},\n",
    "                          missing_policy=MISSING_POLICY,\n",
    "                          fill_missing=0,\n",
    "                          persist=True, \n",
    "                          lstm_1d=False, \n",
    "                          static_to_dynamic=True\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ba264be-01ff-4b52-ade4-baf292b2bf98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7440, 1395)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "116051fc-240e-4b1e-bc30-556b6dfa0956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === SAMPLER ===================================================================\n",
    "\n",
    "\n",
    "train_sampler_builder = SamplerBuilder(\n",
    "    train_dataset,\n",
    "    sampling=\"random\", \n",
    "    processing=\"single-gpu\")\n",
    "\n",
    "test_sampler_builder = SamplerBuilder(\n",
    "    test_dataset,\n",
    "    sampling=\"sequential\", \n",
    "    processing=\"single-gpu\")\n",
    "\n",
    "\n",
    "train_sampler = train_sampler_builder.get_sampler()\n",
    "test_sampler = test_sampler_builder.get_sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b29ef9da-180f-4ed5-b663-63a971d2ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATA LOADER ================================================================\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH , sampler=train_sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH , sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9c2923c-37a4-4a9a-8a75-d0d81a9e785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MODEL ===================================================================\n",
    "\n",
    "model = ConvLSTM(\n",
    "    input_dim =  DYNAMIC_INPUT_SIZE + STATIC_INPUT_SIZE,\n",
    "    output_dim= OUTPUT_SIZE,\n",
    "    hidden_dim = HIDDEN_SIZE,\n",
    "    kernel_size = KERNEL_SIZE,\n",
    "    num_layers = NUM_LSTM_LAYER,\n",
    "    batch_first = True,\n",
    "    bias = False,\n",
    "    return_all_layers = False\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f95b1c0-d930-4678-ac9e-6f473e7c6b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hython.trainer.RNNTrainParams object at 0x7571a49a3af0>\n"
     ]
    }
   ],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode=\"min\", factor=0.5, patience=10)\n",
    "\n",
    "loss_fn = RMSELoss(target_weight=TARGET_WEIGHTS)\n",
    "metric_fn = MSEMetric(target_names=target_names)\n",
    "\n",
    "trainer = HythonTrainer(\n",
    "    RNNTrainParams(\n",
    "               experiment=EXPERIMENT, \n",
    "               target_names=target_names,\n",
    "               metric_func=metric_fn,\n",
    "               loss_func=loss_fn,\n",
    "               #gradient_clip= gradient_clip\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8293ec2f-65a7-4cac-8804-c1b20de0fd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_history, metric_history = train_val(\n",
    "    trainer,\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    EPOCHS,\n",
    "    opt,\n",
    "    lr_scheduler,\n",
    "    SURROGATE_MODEL_OUTPUT,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c0feb-1a0b-4b7d-8746-b0d8c169e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lepochs = list(range(1, EPOCHS + 1))\n",
    "\n",
    "fig, axs = plt.subplots(len(target_names) +1, 1, figsize= (12,10), sharex=True)\n",
    "\n",
    "axs[0].plot(lepochs, [i.detach().cpu().numpy() for i in loss_history['train']], marker='.', linestyle='-', color='b', label='Training')\n",
    "axs[0].plot(lepochs, [i.detach().cpu().numpy() for i in loss_history['val']], marker='.', linestyle='-', color='r', label='Validation')\n",
    "axs[0].set_title('Loss')\n",
    "axs[0].set_ylabel(loss_fn.__name__)\n",
    "axs[0].grid(True)\n",
    "axs[0].legend(bbox_to_anchor=(1,1))\n",
    "\n",
    "for i, variable in enumerate(target_names):\n",
    "    axs[i+1].plot(lepochs, metric_history[f'train_{variable}'], marker='.', linestyle='-', color='b', label='Training')\n",
    "    axs[i+1].plot(lepochs, metric_history[f'val_{variable}'], marker='.', linestyle='-', color='r', label='Validation')\n",
    "    axs[i+1].set_title(variable)\n",
    "    axs[i+1].set_ylabel(metric_fn.__class__.__name__)\n",
    "    axs[i+1].grid(True)\n",
    "    axs[i+1].legend(bbox_to_anchor=(1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
