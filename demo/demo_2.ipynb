{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30de281b-5aee-4e21-a402-d9b7edbd65ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e5f2c-0b5a-4c47-8280-4ff3c150c0e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from hython.preprocess import reshape, apply_normalization\n",
    "from hython.datasets.datasets import LSTMDataset\n",
    "from hython.train_val import train_val\n",
    "from hython.sampler import RegularIntervalSampler, SpaceSampler\n",
    "from hython.metrics import mse_metric\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Dataset\n",
    "\n",
    "from hython.utils import missing_location_idx, reconstruct_from_missing, load\n",
    "from hython.models.lstm import CustomLSTM\n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt\n",
    "from hython.viz import plot_sampler\n",
    "from hython.utils import predict, prepare_for_plotting\n",
    "from hython.viz import map_bias, map_pbias, map_pearson, map_at_timesteps, ts_compare, plot_sampler\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a78cf5-bd72-4a3d-bd18-ce49d0e8fdee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ea7b19-4cdf-4345-9481-ff178e1d0440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dynamic_names = [\"precip\", \"pet\", \"temp\"]\n",
    "static_names = [ 'M', 'thetaS', 'RootingDepth', 'Kext', 'Sl', 'Swood', 'TT', 'KsatHorFrac'] \n",
    "target_names = [ \"vwc\",\"actevap\" ] # \"q_river\"]\n",
    "\n",
    "wflow_model = \"datademo\" # \"alps1km_eobs\" # \"alps1km_cerra\", \n",
    "\n",
    "fn_forcings =  \"forcings.nc\" # 'inmaps_eobs_eobsd_makkink_86400_2015_2019.nc' # \"forcings.nc\"\n",
    "fn_params = \"staticmaps.nc\"\n",
    "fn_targets = \"output.nc\"\n",
    "\n",
    "wd = Path(\"../data\") / wflow_model\n",
    "fp_dynamic_forcings = wd / fn_forcings \n",
    "fp_wflow_static_params = wd / fn_params\n",
    "fp_target = wd / fn_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb9dc94-9f28-4441-a9ad-e95b3a790a8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forcings = xr.open_dataset(fp_dynamic_forcings)\n",
    "params = xr.open_dataset(fp_wflow_static_params)\n",
    "targets = xr.open_dataset(fp_target).isel(lat=slice(None, None, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc89091-8031-4968-8213-1600f65afe59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select forcings, wflow parameters and targets\n",
    "forcings = forcings[dynamic_names]\n",
    "params = params[static_names]\n",
    "targets = targets[target_names] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f520f3ec-054f-4281-abca-24cb2f70529f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forcings   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d42ad07-01b9-4649-9f6b-bff75dbf84b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    forcings = forcings.rename({\"latitude\":\"lat\", \"longitude\":\"lon\"})\n",
    "    params = params.rename({\"latitude\":\"lat\", \"longitude\":\"lon\"})\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34939cd-07a7-499d-bd10-6dd60f1b0236",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8843a5-1a82-4f93-bd8b-87df03b4adcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training \n",
    "\n",
    "spatial_batch_size = 32\n",
    "temporal_sampling_size = 200 \n",
    "seq_length = 30 # days\n",
    "\n",
    "# model \n",
    "\n",
    "hidden_size = 32\n",
    "\n",
    "model_params={\n",
    "    \"input_size\": 3, #number of dynamic predictors - user_input\n",
    "    \"hidden_size\": hidden_size, # user_input\n",
    "    \"output_size\": len(target_names), # number_target - user_input\n",
    "    \"number_static_predictors\": len(static_names), #number of static parameters - user_input \n",
    "\n",
    "}\n",
    "\n",
    "## The used device for training\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909b2f6-5e1d-474c-a0ed-f7287e5fc408",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177d52b6-06fe-40ef-b12c-b9536813f5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remove_lakes = True\n",
    "\n",
    "if remove_lakes:\n",
    "    mask_lakes = (targets.mean(dim = \"time\")[\"actevap\"] == 0).astype(np.bool_)\n",
    "    targets = targets.where(~mask_lakes, np.nan)\n",
    "    forcings = forcings.where(~mask_lakes, np.nan)\n",
    "    params = params.where(~mask_lakes, np.nan)\n",
    "\n",
    "\n",
    "timeslice = slice(\"2016-01-01\",\"2020-12-31\")\n",
    "\n",
    "if timeslice:\n",
    "    forcings = forcings.sel(time=timeslice)\n",
    "    targets = targets.sel(time=timeslice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978f6343-e9a1-4f73-b580-55672adb0aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT IF NOT LOADING PREPROCESSED INPUTS\n",
    "\n",
    "#reshape for training\n",
    "\n",
    "Xd, Xs, Y  = reshape(\n",
    "                   forcings, \n",
    "                   params, \n",
    "                   targets\n",
    "                   )\n",
    "\n",
    "#Define the 2D missing values mask. Sampling \n",
    "\n",
    "missing_mask = np.isnan(params.M).values\n",
    "\n",
    "# UNCOMMENT TO SAVE\n",
    "# np.savez_compressed( surrogate_input_path / f\"{wflow_model}\", Xd=Xd, Xs=Xs, Y=Y, missing_mask = missing_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72fe449-0b84-46d9-a1ef-a753f0f5053f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # loading preprocessed data\n",
    "# Xd, Xs, Y, missing_mask = load(surrogate_input_path, wflow_model, files = [\"Xd\", \"Xs\", \"Y\", \"missing_mask\"])\n",
    "# Xd.shape, Xs.shape, Y.shape, missing_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cda342-cc18-4b45-884c-3ceb9b4780f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the spatial samplers for both training and validation sets. Remeber they should not overlap.\n",
    "\n",
    "intervals = (2, 2) # every n km\n",
    "train_origin = (0, 0)\n",
    "val_origin = (1, 1)\n",
    "\n",
    "spatial_train_sampler = RegularIntervalSampler(intervals = intervals, origin = train_origin)\n",
    "spatial_val_sampler = RegularIntervalSampler(intervals = intervals, origin = val_origin) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53032777-b68f-4ee2-87ed-006bdbd7f1df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the samplers to the 2D domain. The samplers return the cell indices that can be used later in training and validation.\n",
    "data2d  = forcings.to_dataarray().transpose(\"lat\",\"lon\", \"time\", \"variable\")\n",
    "\n",
    "sampler_train_meta = spatial_train_sampler.sampling_idx(data2d, missing_mask)\n",
    "sampler_val_meta = spatial_val_sampler.sampling_idx(data2d, missing_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4520ea49-a25a-475f-a683-0a77fd535dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampler_train_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a40c5e-a7c0-4c34-8b7e-b9859748beee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_sampler(params.Kext, sampler_train_meta, sampler_val_meta, figsize= (10, 10 ), markersize = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91e1ecd-7cf3-42dd-aad4-975bec7894aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## Normalizing v1\n",
    "# # training\n",
    "#Xd[sampler_train_meta.idx_sampled_1d_nomissing], d_m, d_std = apply_normalization(Xd[sampler_train_meta.idx_sampled_1d_nomissing], type = \"spacetime\", how ='standard')\n",
    "#Xs[sampler_train_meta.idx_sampled_1d_nomissing], s_m, s_std = apply_normalization(Xs[sampler_train_meta.idx_sampled_1d_nomissing], type = \"space\", how ='standard')\n",
    "#Y[sampler_train_meta.idx_sampled_1d_nomissing], y_m, y_std = apply_normalization(Y[sampler_train_meta.idx_sampled_1d_nomissing], type = \"spacetime\", how ='standard')\n",
    "# # validation \n",
    "# Xd[sampler_val_meta.idx_sampled_1d_nomissing] = apply_normalization(Xd[sampler_val_meta.idx_sampled_1d_nomissing], type = \"spacetime\", how ='standard', m1 = d_m, m2 = d_std)\n",
    "# Xs[sampler_val_meta.idx_sampled_1d_nomissing] = apply_normalization(Xs[sampler_val_meta.idx_sampled_1d_nomissing], type = \"space\", how ='standard', m1 = s_m, m2 = s_std)\n",
    "# Y[sampler_val_meta.idx_sampled_1d_nomissing] = apply_normalization(Y[sampler_val_meta.idx_sampled_1d_nomissing], type = \"spacetime\", how ='standard', m1 = y_m, m2 = y_std)\n",
    "\n",
    "\n",
    "# # Normalizing v2\n",
    "# # training\n",
    "_, d_m, d_std = apply_normalization(Xd[sampler_train_meta.idx_sampled_1d_nomissing], type = \"spacetime\", how ='standard')\n",
    "_, s_m, s_std = apply_normalization(Xs[sampler_train_meta.idx_sampled_1d_nomissing], type = \"space\", how ='standard')\n",
    "_, y_m, y_std = apply_normalization(Y[sampler_train_meta.idx_sampled_1d_nomissing], type = \"spacetime\", how ='standard')\n",
    "\n",
    "d_m, s_m, y_m, d_std, s_std, y_std\n",
    "# # validation \n",
    "# Xd_valid = apply_normalization(Xd[sampler_val_meta.idx_sampled_1d_nomissing], type = \"spacetime\", how ='standard', m1 = d_m, m2 = d_std)\n",
    "# Xs_valid = apply_normalization(Xs[sampler_val_meta.idx_sampled_1d_nomissing], type = \"space\", how ='standard', m1 = s_m, m2 = s_std)\n",
    "# Y_valid = apply_normalization(Y[sampler_val_meta.idx_sampled_1d_nomissing], type = \"spacetime\", how ='standard', m1 = y_m, m2 = y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e34e05-3eb9-4f75-aab8-b33e62dd5d99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xd = apply_normalization(Xd, type=\"spacetime\", how=\"standard\", m1 = d_m, m2 = d_std)\n",
    "Xs = apply_normalization(Xs, type=\"space\", how=\"standard\",  m1 = s_m, m2 = s_std)\n",
    "Y = apply_normalization(Y, type=\"spacetime\",how=\"standard\", m1 = y_m, m2 = y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e75977-0830-4bea-ad09-0573596c9ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(Xd[11,:400,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee13790d-eadd-4ef9-ae65-47df647016d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.isnan(Xd[sampler_val_meta.idx_sampled_1d_nomissing]).any(), np.isnan(Xs[sampler_val_meta.idx_sampled_1d_nomissing]).any(), np.isnan(Y[sampler_val_meta.idx_sampled_1d_nomissing]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa6bb3-2146-4008-914a-d7c8b70e4f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.isnan(Xd[sampler_train_meta.idx_sampled_1d_nomissing]).any(), np.isnan(Xs[sampler_train_meta.idx_sampled_1d_nomissing]).any(), np.isnan(Y[sampler_train_meta.idx_sampled_1d_nomissing]).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a747bc5a-fe58-4c63-8945-55e660dd9208",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare Model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c76f83-b3f8-4ec6-9b50-03a3db913e00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xs = torch.Tensor(Xs)\n",
    "Xd = torch.Tensor(Xd)\n",
    "Y = torch.Tensor(Y)\n",
    "\n",
    "Xs.shape, Xd.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f680bacd-d2f6-45e4-aa72-53d72b383ce4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init datasets\n",
    "dataset = LSTMDataset(Xd, Y, Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a379cef-7408-45f8-b306-484e932cd2b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sampler = SpaceSampler(dataset, num_samples=1, sampling_indices = sampler_train_meta.idx_sampled_1d_nomissing.tolist())\n",
    "valid_sampler = SpaceSampler(dataset, num_samples=1, sampling_indices = sampler_val_meta.idx_sampled_1d_nomissing.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7823e88-a612-45be-a8a3-3ba316552dc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=spatial_batch_size, shuffle=False, sampler = train_sampler) # implement shuffling in the sampler!\n",
    "val_loader = DataLoader(dataset, batch_size=spatial_batch_size, shuffle=False, sampler = valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512242a5-f53a-45fb-8cd9-247203ee2789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for x,y,s in train_loader:\n",
    "    print(x.shape, y.shape, s.shape)\n",
    "    print(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaedbed-af8b-44da-a677-a56bed8b8706",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b046cecf-ee3c-4b85-b68b-bfd62089e87d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CustomLSTM(model_params)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0751f35d-23e0-4dcf-b67b-b034964f2a87",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train/valid settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f4b4d9-489d-400f-99a3-c079cfe8a715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path2models= \"./checkpoints\" \n",
    "if not os.path.exists(path2models):\n",
    "    os.mkdir(path2models)\n",
    "    \n",
    "    \n",
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "## Set the metric function - here using the same loss function \n",
    "metric_fn = mse_metric\n",
    "\n",
    "## Set the learning rate scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=10)\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "\n",
    "## Set the training parameters\n",
    "params_train={\n",
    "    \"num_epochs\": epochs,\n",
    "    \"temporal_sampling_idx_change_with_epoch\": True,\n",
    "    \"temporal_sampling_size\": temporal_sampling_size,\n",
    "    \"seq_length\": seq_length,\n",
    "    \"ts_range\": Y.shape[1],\n",
    "    \"optimizer\": opt,\n",
    "    \"loss_func\": loss_fn,\n",
    "    \"metric_func\": metric_fn,\n",
    "    \"train_dl\": train_loader, \n",
    "    \"val_dl\": val_loader,\n",
    "    \"lr_scheduler\": lr_scheduler,\n",
    "    \"path2weights\": f\"{path2models}/weights.pt\",\n",
    "    \"device\":device,\n",
    "    \"target_names\": target_names\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aae90c-39ff-42ef-bbaa-77e04da01f40",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run Train/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74736824-bccb-4242-859f-c5984889bc36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, sm_loss_history, sm_metric_history = train_val(model, params_train, plot= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5791b45c-d303-4979-98bf-59f2b2596bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# Extract the loss values\n",
    "train_loss = sm_metric_history['train_vwc']\n",
    "val_loss = sm_metric_history['val_vwc']\n",
    "\n",
    "# Create a list of epochs for the x-axis (e.g., [1, 2, 3, ..., 100])\n",
    "lepochs = list(range(1,params_train[\"num_epochs\"] + 1))\n",
    "\n",
    "# Create the train and validation loss plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lepochs, train_loss, marker='o', linestyle='-', color='b', label='Training Loss')\n",
    "plt.plot(lepochs, val_loss, marker='o', linestyle='-', color='r', label='Validation Loss')\n",
    "plt.title('Validation Loss - SM')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5467c3-9a3f-4bb5-8a9c-027c234e3fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# Extract the loss values\n",
    "train_loss = sm_metric_history['train_actevap']\n",
    "val_loss = sm_metric_history['val_actevap']\n",
    "\n",
    "# Create a list of epochs for the x-axis (e.g., [1, 2, 3, ..., 100])\n",
    "lepochs = list(range(1,params_train[\"num_epochs\"] + 1))\n",
    "\n",
    "# Create the train and validation loss plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lepochs, train_loss, marker='o', linestyle='-', color='b', label='Training Loss')\n",
    "plt.plot(lepochs, val_loss, marker='o', linestyle='-', color='r', label='Validation Loss')\n",
    "plt.title('Validation Loss - SM')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd74d115-5c4d-4b54-acbb-326ead31e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(params_train[\"path2weights\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b659be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "##model= model.to('cuda:0')\n",
    "#model= model.to('cpu')\n",
    "#it = iter(train_loader)\n",
    "# din, static, val = next(it)\n",
    "# din.shape, static.shape, val.shape\n",
    "# plt.figure(figsize=(20,10)) \n",
    "# plt.plot(model(din, static).detach().cpu().numpy()[101,:,1], label =\"model\")\n",
    "# plt.plot(val[101,:,1], label=\"val\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c64054e-d5f3-41ad-ac31-07bbcd13af2e",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3af735-3f21-4832-b5a4-ea2487b003d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ff0d36-ea88-44ec-87d4-846ca3b3b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = predict(Xd, Xs, model, spatial_batch_size, device=\"cpu\")\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f682971d-396c-44ec-ba22-066169ca6117",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon, time = *forcings.to_dataarray().transpose(\"lat\",\"lon\", \"time\", \"variable\").shape[:2], Xd.shape[1]\n",
    "lat*lon ,time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f14ba65-3f29-4e74-aef7-9456efc07523",
   "metadata": {},
   "source": [
    "## SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d917cef-eb03-4209-84a2-fd56223ba1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target, y_pred = prepare_for_plotting(y_target=Y[:,:,[0]], y_pred = yhat[:,:,[0]], shape = (lat, lon, time), coords = targets[target_names].coords)\n",
    "y_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e854d-8684-43d5-815b-3688501cf8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_pbias(y_target, y_pred, figsize = (12, 12)) #, kwargs_imshow = {\"vmin\":-100, \"vmax\":100 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a26edfc-b674-4f66-b2c5-671a18c14566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_pearson(y_target, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2e71c-4c1d-4266-92de-6707c5bf09c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946517c-1310-447e-ad09-11634c2530e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_compare(y_target, y_pred, lat = [45, 46.5, 46.3], lon = [10, 11.3, 11.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e9af6-7eff-4e46-8177-cf2cbff4af07",
   "metadata": {},
   "source": [
    "## ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753fd14-b393-4e1e-b2e2-b6e00e068402",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target_et, y_pred_et = prepare_for_plotting(y_target=Y[:,:,[1]], y_pred = yhat[:,:,[1]], shape = (lat, lon, time), coords = targets.coords)\n",
    "y_target_et.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e51c99f-0990-456d-b9eb-0f9f7cca1eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_pbias(y_target, y_pred, figsize = (12, 12)) #, kwargs_imshow = {\"vmin\":-100, \"vmax\":100 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b309046-9ad2-4fc8-95f5-140b930a1ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_compare(y_target_et, y_pred_et, lat = [46.4, 46.5, 46.3], lon = [11.4, 11.3, 11.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfde4b7-ca03-4dd4-9ff5-4b9070d3de06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e34a36f-44b9-4854-b333-30b9f5f4489b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emulator",
   "language": "python",
   "name": "emulator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
