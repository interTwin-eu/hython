{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "913afcd2-a55e-4804-adf4-699a3f3a660a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf1edf9e-da30-42bb-9bf4-ade44cf3afd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4635e3f-8a34-48ac-b4f5-d871bdfcda0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from hython.datasets.datasets import get_dataset\n",
    "from hython.trainer import train_val\n",
    "from hython.sampler import SamplerBuilder, RegularIntervalDownsampler\n",
    "from hython.metrics import MSEMetric\n",
    "from hython.losses import RMSELoss, nll_loss\n",
    "from hython.utils import read_from_zarr, set_seed\n",
    "from hython.models.cudnnLSTM import CuDNNLSTM\n",
    "from hython.trainer import RNNTrainer, RNNTrainParams\n",
    "from hython.normalizer import Normalizer\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec519dae-bd44-49d1-a9fd-096922865e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hython.metrics import Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a275b19-8ba6-46a0-afd7-8055e88f32fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class CuDNNLSTM_UQ(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_size: int = 24,\n",
    "        dynamic_input_size: int = 3,\n",
    "        static_input_size: int = 9,\n",
    "        output_size: int = 2,\n",
    "        static_to_dynamic: bool = True,\n",
    "        num_layers:int = 1,\n",
    "        dropout:float = 0.0,\n",
    "    ):\n",
    "        super(CuDNNLSTM_UQ, self).__init__()\n",
    "\n",
    "        self.static_to_dynamic = static_to_dynamic\n",
    "\n",
    "        self.fc0 = nn.Linear(dynamic_input_size + static_input_size, hidden_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers = num_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "        self.mean_fc1 = nn.Linear(hidden_size, 12)\n",
    "        self.mean_fc2 = nn.Linear(12, output_size)\n",
    "\n",
    "\n",
    "        self.std_fc3 = nn.Linear(hidden_size, 12)\n",
    "        self.std_fc4 = nn.Linear(12, output_size)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        l1 = self.fc0(x)\n",
    "\n",
    "        lstm_output, (h_n, c_n) = self.lstm(l1)\n",
    "\n",
    "        # Forward pass for the mean \n",
    "        mean = self.mean_fc1(lstm_output)\n",
    "        #mean = torch.abs(self.mean_fc2(mean))\n",
    "        mean = self.mean_fc2(mean)\n",
    "\n",
    "        # Forward pass for the std\n",
    "        std = self.std_fc3(lstm_output)\n",
    "        std = torch.abs(self.std_fc4(std))       \n",
    "        #std = torch.softplus(std) # Softplus to ensure positive std\n",
    "        \n",
    "        return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a78cf5-bd72-4a3d-bd18-ce49d0e8fdee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3186025-caa2-429f-88da-8c9c6b23c292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPERIMENT  = \"exp1\"\n",
    "\n",
    "SURROGATE_INPUT = \"https://eurac-eo.s3.amazonaws.com/INTERTWIN/SURROGATE_INPUT/adg1km_eobs_preprocessed.zarr/\"\n",
    "\n",
    "SURROGATE_MODEL_OUTPUT = f\"path/to/model/output/directory/{EXPERIMENT}.pt\"\n",
    "\n",
    "TMP_STATS = \"path/to/temporary/stats/directory\" \n",
    "\n",
    "# === FILTER ==============================================================\n",
    "\n",
    "# train/test temporal range\n",
    "train_temporal_range = slice(\"2012-01-01\",\"2018-12-31\")\n",
    "test_temporal_range = slice(\"2019-01-01\", \"2019-12-31\")\n",
    "\n",
    "# variables\n",
    "dynamic_names = [\"precip\", \"pet\", \"temp\"] \n",
    "static_names = [ \"thetaS\", \"thetaR\", \"KsatVer\", \"SoilThickness\", \"RootingDepth\", \"f\", \"Swood\", \"Sl\", \"Kext\"]\n",
    "target_names = [\"vwc\", \"actevap\"]# [\"vwc\", \"actevap\", \"snow\", \"snowwater\"] \n",
    "\n",
    "# === MASK ========================================================================================\n",
    "\n",
    "mask_names = [\"mask_missing\", \"mask_lake\"] # names depends on preprocessing application\n",
    "\n",
    "# === DATASET ========================================================================================\n",
    "\n",
    "DATASET = \"LSTMDataset\"\n",
    "\n",
    "# == MODEL  ========================================================================================\n",
    "\n",
    "HIDDEN_SIZE = 24\n",
    "DYNAMIC_INPUT_SIZE = len(dynamic_names)\n",
    "STATIC_INPUT_SIZE = len(static_names)\n",
    "OUTPUT_SIZE = len(target_names)\n",
    "\n",
    "TARGET_WEIGHTS = {t:1/len(target_names) for t in target_names}\n",
    "\n",
    "\n",
    "# === SAMPLER/TRAINER ===================================================================================\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH = 256\n",
    "SEED = 42\n",
    "\n",
    "# downsampling, speeds up the training!\n",
    "\n",
    "# - spatial\n",
    "\n",
    "DONWSAMPLING = False\n",
    "TRAIN_INTERVAL = [3,3]\n",
    "TRAIN_ORIGIN = [0,0]\n",
    "\n",
    "TEST_INTERVAL = [3,3]\n",
    "TEST_ORIGIN = [2,2]\n",
    "\n",
    "# - temporal\n",
    "TEMPORAL_SUBSAMPLING = True\n",
    "TEMPORAL_SUBSET = [150, 150] # n of sequences \n",
    "SEQ_LENGTH = 360\n",
    "\n",
    "\n",
    "assert sum(v for v in TARGET_WEIGHTS.values()) == 1, \"check target weights\"\n",
    "TARGET_INITIALS = \"\".join([i[0].capitalize() for i in target_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c67bf4f-55e3-46fc-927b-72711d831f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "221b3d8f-3c17-4b4b-bd85-8cfc1c765f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xd = (\n",
    "    read_from_zarr(url=SURROGATE_INPUT, group=\"xd\", multi_index=\"gridcell\")\n",
    "    .sel(time=train_temporal_range)\n",
    "    .xd.sel(feat=dynamic_names)\n",
    ")\n",
    "Xs = read_from_zarr(url=SURROGATE_INPUT, group=\"xs\", multi_index=\"gridcell\").xs.sel(\n",
    "    feat=static_names\n",
    ")\n",
    "Y = (\n",
    "    read_from_zarr(url=SURROGATE_INPUT, group=\"y\", multi_index=\"gridcell\")\n",
    "    .sel(time=train_temporal_range)\n",
    "    .y.sel(feat=target_names)\n",
    ")\n",
    "\n",
    "SHAPE = Xd.attrs[\"shape\"]\n",
    "\n",
    "\n",
    "# === READ TEST ===================================================================\n",
    "\n",
    "Y_test = (\n",
    "    read_from_zarr(url=SURROGATE_INPUT, group=\"y\", multi_index=\"gridcell\")\n",
    "    .sel(time=test_temporal_range)\n",
    "    .y.sel(feat=target_names)\n",
    ")\n",
    "Xd_test = (\n",
    "    read_from_zarr(url=SURROGATE_INPUT, group=\"xd\", multi_index=\"gridcell\")\n",
    "    .sel(time=test_temporal_range)\n",
    "    .xd.sel(feat=dynamic_names)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "314c3596-a997-4b68-a94e-e7b48c3267e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masks = (\n",
    "    read_from_zarr(url=SURROGATE_INPUT, group=\"mask\")\n",
    "    .mask.sel(mask_layer=mask_names)\n",
    "    .any(dim=\"mask_layer\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1f6c0de-d71a-430b-91fc-52fff2d259b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DONWSAMPLING:\n",
    "    train_downsampler = RegularIntervalDownsampler(\n",
    "        intervals=TRAIN_INTERVAL, origin=TRAIN_ORIGIN\n",
    "    )       \n",
    "    test_downsampler = RegularIntervalDownsampler(\n",
    "        intervals=TEST_INTERVAL, origin=TEST_ORIGIN\n",
    "    )\n",
    "else:\n",
    "    train_downsampler, test_downsampler = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "419b87d9-a610-4933-8fd1-6579aefbc99f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer_dynamic = Normalizer(method=\"standardize\",\n",
    "                                type=\"spacetime\", axis_order=\"NTC\")\n",
    "normalizer_static = Normalizer(method=\"standardize\",\n",
    "                               type=\"space\", axis_order=\"NTC\")\n",
    "normalizer_target = Normalizer(method=\"standardize\", type=\"spacetime\",\n",
    "                               axis_order=\"NTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4de2a80e-82c1-4845-9b30-58fe6da906e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(DATASET)(\n",
    "        Xd,\n",
    "        Y,\n",
    "        Xs,\n",
    "        original_domain_shape=SHAPE,\n",
    "        mask=masks,\n",
    "        downsampler=train_downsampler,\n",
    "        normalizer_dynamic=normalizer_dynamic,\n",
    "        normalizer_static=normalizer_static,\n",
    "        normalizer_target=normalizer_target\n",
    ")\n",
    "test_dataset = get_dataset(DATASET)(\n",
    "        Xd_test,\n",
    "        Y_test,\n",
    "        Xs,\n",
    "        original_domain_shape=SHAPE,\n",
    "        mask=masks,\n",
    "        downsampler=test_downsampler,\n",
    "        normalizer_dynamic=normalizer_dynamic,\n",
    "        normalizer_static=normalizer_static,\n",
    "        normalizer_target=normalizer_target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "116051fc-240e-4b1e-bc30-556b6dfa0956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === SAMPLER ===================================================================\n",
    "\n",
    "\n",
    "train_sampler_builder = SamplerBuilder(\n",
    "    train_dataset,\n",
    "    sampling=\"random\", \n",
    "    processing=\"single-gpu\")\n",
    "\n",
    "test_sampler_builder = SamplerBuilder(\n",
    "    test_dataset,\n",
    "    sampling=\"sequential\", \n",
    "    processing=\"single-gpu\")\n",
    "\n",
    "\n",
    "train_sampler = train_sampler_builder.get_sampler()\n",
    "test_sampler = test_sampler_builder.get_sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b29ef9da-180f-4ed5-b663-63a971d2ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATA LOADER ===================================================================\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH , sampler=train_sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH , sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9c2923c-37a4-4a9a-8a75-d0d81a9e785e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CuDNNLSTM(\n",
       "  (fc0): Linear(in_features=12, out_features=24, bias=True)\n",
       "  (lstm): LSTM(24, 24, batch_first=True)\n",
       "  (fc1): Linear(in_features=24, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === MODEL ===================================================================\n",
    "\n",
    "model = CuDNNLSTM(\n",
    "                hidden_size=HIDDEN_SIZE, \n",
    "                dynamic_input_size=DYNAMIC_INPUT_SIZE,\n",
    "                static_input_size=STATIC_INPUT_SIZE, \n",
    "                output_size=OUTPUT_SIZE\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9953c1db-4844-4d63-ab1b-156acb9af301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CuDNNLSTM_UQ(\n",
       "  (fc0): Linear(in_features=12, out_features=24, bias=True)\n",
       "  (lstm): LSTM(24, 24, batch_first=True)\n",
       "  (mean_fc1): Linear(in_features=24, out_features=12, bias=True)\n",
       "  (mean_fc2): Linear(in_features=12, out_features=2, bias=True)\n",
       "  (std_fc3): Linear(in_features=24, out_features=12, bias=True)\n",
       "  (std_fc4): Linear(in_features=12, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uq = CuDNNLSTM_UQ(output_size=2)\n",
    "model_uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f95b1c0-d930-4678-ac9e-6f473e7c6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "lr_scheduler = ReduceLROnPlateau(opt, mode=\"min\", factor=0.5, patience=10)\n",
    "\n",
    "loss_fn = RMSELoss(target_weight=TARGET_WEIGHTS)\n",
    "loss_fn = nll_loss(target_weight=TARGET_WEIGHTS)\n",
    "\n",
    "metric_fn = MSEMetric(target_names=target_names)\n",
    "\n",
    "trainer = RNNTrainer(\n",
    "    RNNTrainParams(\n",
    "            experiment=EXPERIMENT,\n",
    "            temporal_subsampling=TEMPORAL_SUBSAMPLING, \n",
    "            temporal_subset=TEMPORAL_SUBSET, \n",
    "            seq_length=SEQ_LENGTH, \n",
    "            target_names=target_names,\n",
    "            metric_func=metric_fn,\n",
    "            loss_func=loss_fn)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7caaa8-b241-46fa-8235-a991062ef986",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_history, metric_history = train_val(\n",
    "    trainer,\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    EPOCHS,\n",
    "    opt,\n",
    "    lr_scheduler,\n",
    "    SURROGATE_MODEL_OUTPUT,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c0feb-1a0b-4b7d-8746-b0d8c169e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lepochs = list(range(1, EPOCHS + 1))\n",
    "\n",
    "fig, axs = plt.subplots(len(target_names) +1, 1, figsize= (12,10), sharex=True)\n",
    "\n",
    "axs[0].plot(lepochs, [i.detach().cpu().numpy() for i in loss_history['train']], marker='.', linestyle='-', color='b', label='Training')\n",
    "axs[0].plot(lepochs, [i.detach().cpu().numpy() for i in loss_history['val']], marker='.', linestyle='-', color='r', label='Validation')\n",
    "axs[0].set_title('Loss')\n",
    "axs[0].set_ylabel(loss_fn.__name__)\n",
    "axs[0].grid(True)\n",
    "axs[0].legend(bbox_to_anchor=(1,1))\n",
    "\n",
    "for i, variable in enumerate(target_names):\n",
    "    axs[i+1].plot(lepochs, metric_history[f'train_{variable}'], marker='.', linestyle='-', color='b', label='Training')\n",
    "    axs[i+1].plot(lepochs, metric_history[f'val_{variable}'], marker='.', linestyle='-', color='r', label='Validation')\n",
    "    axs[i+1].set_title(variable)\n",
    "    axs[i+1].set_ylabel(metric_fn.__class__.__name__)\n",
    "    axs[i+1].grid(True)\n",
    "    axs[i+1].legend(bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "1172d488-9836-4b4f-abc3-56b4af0a3c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CuDNNLSTM_UQ(\n",
       "  (fc0): Linear(in_features=12, out_features=24, bias=True)\n",
       "  (lstm): LSTM(24, 24, batch_first=True)\n",
       "  (mean_fc1): Linear(in_features=24, out_features=12, bias=True)\n",
       "  (mean_fc2): Linear(in_features=12, out_features=1, bias=True)\n",
       "  (std_fc3): Linear(in_features=24, out_features=12, bias=True)\n",
       "  (std_fc4): Linear(in_features=12, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uq = CuDNNLSTM_UQ(output_size=1)\n",
    "model_uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "dc140825-aa62-46fb-95a8-51a6ec9452e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 2557, 3])\n",
      "torch.Size([256, 9])\n",
      "torch.Size([256, 2557, 2])\n"
     ]
    }
   ],
   "source": [
    "for dynamic_b, static_b, targets_b in train_loader:\n",
    "    print(dynamic_b.shape)\n",
    "    print(static_b.shape)\n",
    "    print(targets_b.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "2ab65c5a-955a-4a07-a7e5-a2668c5fd549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2557"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_range =  next(iter(train_loader))[0].shape[1]\n",
    "time_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "142b8a57-d992-4ecb-8a8d-18877ab0b532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 2554, 2555, 2556])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_index = np.arange(0, time_range)\n",
    "time_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "05d3fffc-6fe5-4ace-8b02-ae8a5c2e9662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([72, 360, 3])\n",
      "torch.Size([72, 360, 2])\n",
      "torch.Size([72, 360, 9])\n",
      "torch.Size([72, 360, 12])\n"
     ]
    }
   ],
   "source": [
    "for dynamic_b, static_b, targets_b in train_loader:\n",
    "    batch_temporal_loss = 0            \n",
    "\n",
    "    # every batch\n",
    "    #self.temporal_index( dynamic_b.shape[1])\n",
    "\n",
    "    for t in time_index:  # time_index could be a subset of time indices\n",
    "        # filter sequence\n",
    "        dynamic_bt = dynamic_b[:, t : (t + 360)].to(device)\n",
    "        targets_bt = targets_b[:, t : (t + 360)].to(device)\n",
    "        \n",
    "        # static --> dynamic size (repeat time dim)\n",
    "        static_bt = static_b.unsqueeze(1).repeat(1, dynamic_bt.size(1), 1).to(device)\n",
    "        \n",
    "        x_concat = torch.cat(\n",
    "            (dynamic_bt, static_bt),\n",
    "            dim=-1,\n",
    "        )\n",
    "        break\n",
    "        output = model(x_concat)\n",
    "\n",
    "print(dynamic_bt.shape)\n",
    "print(targets_bt.shape)\n",
    "print(static_bt.shape)\n",
    "print(x_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "2aebde6b-e404-4bb7-9c1f-c33bbca6a02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CuDNNLSTM_UQ(\n",
       "  (fc0): Linear(in_features=12, out_features=24, bias=True)\n",
       "  (lstm): LSTM(24, 24, batch_first=True)\n",
       "  (mean_fc1): Linear(in_features=24, out_features=12, bias=True)\n",
       "  (mean_fc2): Linear(in_features=12, out_features=1, bias=True)\n",
       "  (std_fc3): Linear(in_features=24, out_features=12, bias=True)\n",
       "  (std_fc4): Linear(in_features=12, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uq = CuDNNLSTM_UQ(output_size=1)\n",
    "model_uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "0626f68e-80c7-42e2-96b1-124d4255cc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([72, 360, 1])\n",
      "torch.Size([72, 360, 1])\n"
     ]
    }
   ],
   "source": [
    "output1 = model_uq(x_concat)\n",
    "mean_outputs = output1[0]#.shape\n",
    "std_outputs = output1[1] #.shape\n",
    "\n",
    "print(mean_outputs.shape)\n",
    "print(std_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "8b779558-0d33-421b-8061-79e6e424c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_step(arr, steps=-1):\n",
    "    \"\"\"Return the n steps that should be predicted\"\"\"\n",
    "    return arr[:, steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "f64ef221-a258-4d8d-8a17-4d92e30d23c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean & std for the last step\n",
    "mean_outputs_l = predict_step(mean_outputs, steps=-1)\n",
    "std_outputs_l = predict_step(std_outputs, steps=-1)\n",
    "target = predict_step(targets_bt, steps=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "897f7b28-a308-4cfb-9bab-8d3a54fc46df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1388, 0.1482, 0.1898, 0.1870, 0.1928, 0.1722, 0.1650, 0.2206,\n",
       "        0.1707, 0.1607, 0.1193, 0.1531, 0.1312, 0.1467, 0.1281, 0.1221, 0.1448,\n",
       "        0.1932, 0.2019, 0.1272, 0.1145, 0.2065, 0.1896, 0.1488, 0.2050, 0.1964,\n",
       "        0.1662, 0.2078, 0.1626, 0.2075, 0.1897, 0.1616, 0.2069, 0.1559, 0.1847,\n",
       "        0.2019, 0.1305, 0.2109, 0.1898, 0.1579, 0.1635, 0.1553, 0.1904, 0.1980,\n",
       "        0.1293, 0.2036, 0.1855, 0.1947, 0.2072, 0.1480, 0.1729, 0.1885, 0.1702,\n",
       "        0.1487, 0.2124, 0.1338, 0.1615, 0.1175, 0.1717, 0.1327, 0.1640, 0.1819,\n",
       "        0.2238, 0.1655, 0.2044, 0.1747, 0.1923, 0.1338, 0.1237, 0.1978, 0.1632],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_outputs_l[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "e2f687c0-f70e-4bf3-9591-dea53c1e8738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1149, -0.1172, -0.0622, -0.1274, -0.0982, -0.1038, -0.1549, -0.1286,\n",
       "        -0.0864, -0.1077, -0.0671, -0.1199, -0.1016, -0.1021, -0.1969, -0.0946,\n",
       "        -0.1836, -0.1057, -0.1627, -0.1808, -0.1001, -0.1105, -0.0941, -0.1365,\n",
       "        -0.1213, -0.1500, -0.1589, -0.0924, -0.0294,  0.0159, -0.0645, -0.0498,\n",
       "        -0.1546, -0.1217, -0.1098, -0.1379, -0.0771, -0.1428, -0.1187, -0.1304,\n",
       "        -0.1053, -0.1140, -0.1037, -0.1473, -0.1499, -0.1009, -0.0682, -0.0718,\n",
       "        -0.1540, -0.1487, -0.1160, -0.1366, -0.1136, -0.1266, -0.0650, -0.0944,\n",
       "        -0.1107, -0.1085, -0.1086, -0.0467, -0.1203, -0.1054, -0.1646, -0.1188,\n",
       "        -0.0933, -0.1201, -0.1538, -0.1326, -0.1190, -0.1129, -0.1234, -0.1703],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_outputs_l[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "8bce8526-4db4-4188-a028-799d17d6c866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist = Normal(mean_outputs_l[:,0], std_outputs_l[:,0])\n",
    "#nll = -dist.log_prob(target[:,0]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "f332e56d-0c5e-45b7-bbc5-afc36fcd45a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2285, -0.5555, -0.4903, -0.2427, -0.2579, -0.2270, -0.3399, -0.3831,\n",
       "        -0.0924, -0.3492, -0.4093, -0.7076, -0.4578, -0.6120, -0.5005, -0.6363,\n",
       "        -0.6842, -0.5136, -0.2251, -0.1812, -0.6428, -0.7480, -0.1587, -0.2437,\n",
       "        -0.4859, -0.1660, -0.2086, -0.3755, -0.1525, -0.3973, -0.1539, -0.2434,\n",
       "        -0.4036, -0.1567, -0.4398, -0.2700, -0.1811, -0.6173, -0.1373, -0.2431,\n",
       "        -0.4266, -0.3921, -0.4433, -0.2398, -0.2008, -0.6265, -0.1728, -0.2660,\n",
       "        -0.2172, -0.1552, -0.4919, -0.3361, -0.2495, -0.3520, -0.4868, -0.1306,\n",
       "        -0.5925, -0.4040, -0.7223, -0.3431, -0.6010, -0.3891, -0.2853, -0.0780,\n",
       "        -0.3799, -0.1687, -0.3258, -0.2297, -0.5922, -0.6707, -0.2017, -0.3936],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.entropy()#.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c17bdd64-7064-446a-b7ef-90eb62c57b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2287)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = Normal(-0.1149, 0.1925)\n",
    "dist.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "3a4cc234-5319-40f8-89fd-167afadc1113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m Method to compute the entropy using Bregman divergence of the log normalizer.\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/basic/lib/python3.11/site-packages/torch/distributions/normal.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??dist.entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7bcdfd81-ea31-40d6-90fd-117ed50f233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "## Negative log-likelihood (NLL) loss\n",
    "def nll_loss(y, distr_mean, distr_std):\n",
    "    # Normal distribution\n",
    "    dist = Normal(distr_mean, distr_std)\n",
    "    return -dist.log(y).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "504ca978-8c4f-435c-b792-a4894a11811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "\n",
    "class nll_loss(_Loss):\n",
    "    __name__ = \"NLL\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_weight: dict = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Negative log-likelihood (NLL) loss for normal distribution.\n",
    "\n",
    "         Parameters:\n",
    "         target_weight: List of targets that contribute in the loss computation, with their associated weights.\n",
    "                        In the form {target: weight}\n",
    "        \"\"\"\n",
    "\n",
    "        super(nll_loss, self).__init__()\n",
    "        self.target_weight = target_weight\n",
    "\n",
    "    def forward(self, y_true, distr_mean, distr_std):\n",
    "        \"\"\"\n",
    "        Calculate the negative log-likelihood of the underlying normal distribution.\n",
    "\n",
    "        Parameters:\n",
    "        y_true (torch.Tensor): The true values.\n",
    "        distr_mean (torch.Tensor): The predicted mean values. \n",
    "        distr_std (torch.Tensor): The predicted std values.\n",
    "\n",
    "        Shape\n",
    "        y_true: torch.Tensor of shape (N, T).\n",
    "        distr_mean: torch.Tensor of shape (N, T).\n",
    "        distr_std: torch.Tensor of shape (N, T).\n",
    "        (256,3) means 256 samples with 3 targets.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: The NLL loss.\n",
    "        \"\"\"\n",
    "        if self.target_weight is None:\n",
    "            dist = Normal(distr_mean, distr_std)\n",
    "            total_nll_loss = -dist.log_prob(y_true).mean()\n",
    "\n",
    "        else:\n",
    "            total_nll_loss = 0\n",
    "            for idx, k in enumerate(self.target_weight):\n",
    "                w = self.target_weight[k]\n",
    "                dist = Normal(distr_mean[:, idx], distr_std[:, idx])\n",
    "                nll_loss = -dist.log_prob(y_true[:, idx]).mean()\n",
    "                loss = nll_loss * w\n",
    "                total_nll_loss += loss\n",
    "\n",
    "        return total_nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "541a8009-871c-4f9f-ab8b-3c15b65369de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "t = [\"ah\", \"by\"]\n",
    "if isinstance(t, list):\n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e941cf-7b37-447e-b6b1-43865b98efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(loss_func, output, target, opt=None, gradient_clip = None, model=None, add_losses: dict = {}):\n",
    "\n",
    "    if isinstance(output, list):\n",
    "        loss = loss_func(target, output[0], output[1])\n",
    "        \n",
    "    elif target.shape[-1] == 1:\n",
    "        target = torch.squeeze(target)\n",
    "        output = torch.squeeze(output)\n",
    "        loss = loss_func(target, output)\n",
    "    else:\n",
    "        loss = loss_func(target, output)\n",
    "\n",
    "    # compound more losses, in case dict is not empty\n",
    "    # TODO: add user-defined weights\n",
    "    for k in add_losses:\n",
    "        loss += add_losses[k]\n",
    "\n",
    "    if opt is not None: \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        if gradient_clip is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), **gradient_clip)\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c4cb65-6f1f-4d98-8f8f-91586ea80817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntropyMetric(Metric):\n",
    "    \"\"\"\n",
    "    Entropy\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred (numpy.array): The true values.\n",
    "    y_true (numpy.array): The predicted values.\n",
    "    target_names: List of targets that contribute in the loss computation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary of Entropy metric for each target. {'target': entropy_metric}\n",
    "    \n",
    "    \"\"\" \n",
    "    metrics = {}\n",
    "    for idx, target in enumerate(target_names)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061fe7c-99a0-4ae6-82f8-9a8210c56cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    metrics = {}\n",
    "\n",
    "    for idx, target in enumerate(target_names):\n",
    "        observed = y_true[:, idx]\n",
    "        simulated = y_pred[:, idx]\n",
    "        r = np.corrcoef(observed, simulated)[1, 0]\n",
    "        alpha = np.std(simulated, ddof=1) / np.std(observed, ddof=1)\n",
    "        beta = np.mean(simulated) / np.mean(observed)\n",
    "        kge = 1 - np.sqrt(\n",
    "            np.power(r - 1, 2) + np.power(alpha - 1, 2) + np.power(beta - 1, 2)\n",
    "        )\n",
    "        metrics[target] = kge\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402e1f81-15c7-435a-96bd-854a377a47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSEMetric(Metric):\n",
    "    \"\"\"\n",
    "    Mean Squared Error (MSE)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred (numpy.array): The true values.\n",
    "    y_true (numpy.array): The predicted values.\n",
    "    target_names: List of targets that contribute in the loss computation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary of Entropy metric for each target. {'target': entropy_metric}\n",
    "    \n",
    "    \"\"\"\n",
    "    def __call__(self, y_pred, y_true, target_names: list[str]):\n",
    "        return metric_decorator(y_pred, y_true, target_names)(compute_mse)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "91de0743-6a6a-4239-b9c7-1bd19cf199b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_loss1 = nll_loss(target_weight=TARGET_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2d10f226-022a-40be-876e-92405fdda1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(126.3684, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll_loss1(target, mean_outputs_l, std_outputs_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fbc26e-fd93-46a2-b801-ecee59a74113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network model for the mean and std\n",
    "class ProbabilisticModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ProbabilisticModel, self).__init__()\n",
    "        \n",
    "        # Mean network\n",
    "        self.mean_fc1 = nn.Linear(input_size, 100)\n",
    "        self.mean_fc2 = nn.Linear(100, 50)\n",
    "        self.mean_out = nn.Linear(50, 1)\n",
    "\n",
    "        # Standard deviation network\n",
    "        self.std_fc1 = nn.Linear(input_size, 100)\n",
    "        self.std_fc2 = nn.Linear(100, 50)\n",
    "        self.std_fc3 = nn.Linear(50, 20)\n",
    "        self.std_out = nn.Linear(20, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass for the mean\n",
    "        mean = F.relu(self.mean_fc1(x))\n",
    "        mean = F.relu(self.mean_fc2(mean))\n",
    "        mean = self.mean_out(mean)\n",
    "        \n",
    "        # Forward pass for the std deviation\n",
    "        std = F.relu(self.std_fc1(x))\n",
    "        std = F.dropout(std, p=0.1, training=self.training) # Dropout\n",
    "        std = F.relu(self.std_fc2(std))\n",
    "        std = F.dropout(std, p=0.1, training=self.training) # Dropout\n",
    "        std = F.relu(self.std_fc3(std))\n",
    "        std = torch.softplus(self.std_out(std)) # Softplus to ensure positive std\n",
    "        \n",
    "        return mean, std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
