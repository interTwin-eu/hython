{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "913afcd2-a55e-4804-adf4-699a3f3a660a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28047b41-d328-4911-b525-366a787cb584",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iferrario/.local/miniforge/envs/emulator/lib/python3.11/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "ERROR 1: PROJ: proj_create_from_database: Open of /home/iferrario/.local/miniforge/envs/emulator/share/proj failed\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader # type: ignore\n",
    "import torch.optim as optim # type: ignore\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau # type: ignore\n",
    "from torch import nn # type: ignore\n",
    "\n",
    "from hython.models.cudnnLSTM import CuDNNLSTM\n",
    "from hython.datasets.datasets import get_dataset\n",
    "from hython.sampler import *\n",
    "from hython.normalizer import Normalizer\n",
    "from hython.trainer import *\n",
    "from hython.utils import read_from_zarr, missing_location_idx, set_seed, prepare_for_plotting\n",
    "from hython.evaluator import predict\n",
    "from hython.trainer import train_val\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from hython.viz import map_kge, map_bias, map_pbias, map_pearson, map_rmse, map_at_timesteps, ts_compare, plot_sampler, compute_kge_parallel, ts_plot, map_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a78cf5-bd72-4a3d-bd18-ce49d0e8fdee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "928fa390-cc03-4046-90f2-48250df953ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## inputs\n",
    "\n",
    "# wflow model name, i.e. surrogate input file produced by the preprocessing application\n",
    "\n",
    "file_surr_input = \"https://eurac-eo.s3.amazonaws.com/INTERTWIN/SURROGATE_INPUT/adg1km_eobs_preprocessed.zarr/\"\n",
    "\n",
    "surr_model =  \"test.pt\"\n",
    "experiment =  \"test\"  \n",
    "\n",
    "\n",
    "dir_wflow_model = \"adg1km_eobs\"\n",
    "file_target = \"run_default/output.nc\"\n",
    "\n",
    "# input directory \n",
    "dir_surr_input = \"/mnt/CEPH_PROJECTS/InterTwin/hydrologic_data/surrogate_input\"\n",
    "dir_surr_model = \"/home/iferrario/dev/itwinai/use-cases/eurac/tmp\"\n",
    "dir_wflow_input = \"/mnt/CEPH_PROJECTS/InterTwin/Wflow/models\"\n",
    "\n",
    "## outputs\n",
    "\n",
    "# directory to save the statistics computed during the normalization\n",
    "dir_stats_output = \"/home/iferrario/dev/itwinai/use-cases/eurac/tmp\"\n",
    "\n",
    "# === FILTER ==============================================================\n",
    "\n",
    "# select temporal range\n",
    "train_temporal_range = [\"2016-01-01\", \"2018-12-31\"] \n",
    "valid_temporal_range = [\"2019-01-01\", \"2020-12-31\"]\n",
    "\n",
    "# select variable names\n",
    "dynamic_names = [\"precip\", \"pet\", \"temp\"]\n",
    "static_names = [ \"wflow_dem\", \"Slope\", \"wflow_uparea\"]  #[ 'thetaS', 'thetaR', 'RootingDepth', 'Swood','KsatVer', \"Sl\"] \n",
    "target_names = [ \"runoff_river\"]\n",
    "\n",
    "# === MASK ========================================================================================\n",
    "\n",
    "mask_names = [\"mask_missing\", \"mask_lake\"] # names depends on preprocessing application\n",
    "\n",
    "# == MODEL  ========================================================================================\n",
    "\n",
    "# DL model hyper parameters\n",
    "HIDDEN_SIZE = 24\n",
    "DYNAMIC_INPUT_SIZE = len(dynamic_names)\n",
    "STATIC_INPUT_SIZE = len(static_names)\n",
    "OUTPUT_SIZE = len(target_names)\n",
    "TARGET_WEIGHTS = {t:0.5 for t in target_names}\n",
    "\n",
    "BATCH = 256\n",
    "\n",
    "# === METRICS =====================================================================================\n",
    "\n",
    "metrics = { \n",
    "  \"vwc\": [\"rmse\", \"kge\",  \"pbias\"],\n",
    "  \"actevap\": [\"rmse\", \"kge\",  \"pbias\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aefb1d13-4482-4917-afb4-4a1d0dde6e22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "file_surr_model = f\"{dir_surr_model}/{surr_model}\"\n",
    "\n",
    "file_wflow_target = f\"{dir_wflow_input}/{dir_wflow_model}/{file_target}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a19f2e6-6f5c-425c-b957-03878b7cb799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_temporal_range = slice(*train_temporal_range)\n",
    "valid_temporal_range = slice(*valid_temporal_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99efcc36-3d67-4231-96e5-68e2e83fc71b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === READ TRAIN ============================================================= \n",
    "\n",
    "Xs = read_from_zarr(url=file_surr_input, group=\"xs\", multi_index=\"gridcell\").xs.sel(\n",
    "     feat=static_names\n",
    " )\n",
    "\n",
    "\n",
    "# === READ TEST ============================================================= \n",
    "\n",
    "Xd_test = (\n",
    "    read_from_zarr(url=file_surr_input, group=\"xd\", multi_index=\"gridcell\")\n",
    "    .sel(time=valid_temporal_range)\n",
    "    .xd.sel(feat=dynamic_names)\n",
    ")\n",
    "Y_test = (\n",
    "    read_from_zarr(url=file_surr_input, group=\"y\", multi_index=\"gridcell\")\n",
    "    .sel(time=valid_temporal_range)\n",
    "    .y.sel(feat=target_names)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ba11d1e-c6aa-477d-8ee4-e04171d8672c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === MASK ============================================================= \n",
    "masks = (\n",
    "    read_from_zarr(url=file_surr_input, group=\"mask\")\n",
    "    .mask.sel(mask_layer=mask_names)\n",
    "    .any(dim=\"mask_layer\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "279ff65a-09d6-49ad-9e71-f23d06ecef02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read from /home/iferrario/dev/itwinai/use-cases/eurac/tmp/xd.npy\n",
      "read from /home/iferrario/dev/itwinai/use-cases/eurac/tmp/xs.npy\n",
      "read from /home/iferrario/dev/itwinai/use-cases/eurac/tmp/y.npy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (40140,3) (1,6) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m normalizer_target\u001b[38;5;241m.\u001b[39mread_stats(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdir_stats_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/y.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m Xd_test \u001b[38;5;241m=\u001b[39m normalizer_dynamic\u001b[38;5;241m.\u001b[39mnormalize(Xd_test)\n\u001b[0;32m---> 16\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[43mnormalizer_static\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m Y_test \u001b[38;5;241m=\u001b[39m normalizer_target\u001b[38;5;241m.\u001b[39mnormalize(Y_test)\n",
      "File \u001b[0;32m~/dev/hython/hython/normalizer.py:110\u001b[0m, in \u001b[0;36mNormalizer.normalize\u001b[0;34m(self, arr, read_from, write_to)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scale_func(arr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomputed_stats)\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscale_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomputed_stats\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/hython/hython/normalizer.py:11\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(arr, axis, m1, m2)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m expand_dims, nanmean, nanstd, nanmin, nanmax\n\u001b[1;32m      6\u001b[0m FUNCS \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminmax\u001b[39m\u001b[38;5;124m\"\u001b[39m: [nanmin, nanmax], \n\u001b[1;32m      7\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstandardize\u001b[39m\u001b[38;5;124m\"\u001b[39m: [nanmean, nanstd]}\n\u001b[1;32m      9\u001b[0m SCALER \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminmax\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m arr, axis, m1, m2: (arr \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(m1, axis\u001b[38;5;241m=\u001b[39maxis)) \u001b[38;5;241m/\u001b[39m (np\u001b[38;5;241m.\u001b[39mexpand_dims(m2, axis\u001b[38;5;241m=\u001b[39maxis)  \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(m1, axis\u001b[38;5;241m=\u001b[39maxis)),\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstandardize\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m arr, axis, m1, m2: (\u001b[43marr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m/\u001b[39m expand_dims(m2, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m     12\u001b[0m     }\n\u001b[1;32m     14\u001b[0m SCALER_XARRAY \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminmax\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m arr, axis, m1, m2: (arr \u001b[38;5;241m-\u001b[39m m1)\u001b[38;5;241m/\u001b[39m (m2 \u001b[38;5;241m-\u001b[39m m1),\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstandardize\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m arr, axis, m1, m2: (arr \u001b[38;5;241m-\u001b[39m m1)\u001b[38;5;241m/\u001b[39m m2\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     19\u001b[0m DENORM_XARRAY \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstandardize\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m arr, m1, m2: (arr \u001b[38;5;241m*\u001b[39m m2) \u001b[38;5;241m+\u001b[39m m1\n\u001b[1;32m     21\u001b[0m }\n",
      "File \u001b[0;32m~/.local/miniforge/envs/emulator/lib/python3.11/site-packages/xarray/core/_typed_ops.py:248\u001b[0m, in \u001b[0;36mDataArrayOpsMixin.__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: DaCompatible) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_binary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/miniforge/envs/emulator/lib/python3.11/site-packages/xarray/core/dataarray.py:4657\u001b[0m, in \u001b[0;36mDataArray._binary_op\u001b[0;34m(self, other, f, reflexive)\u001b[0m\n\u001b[1;32m   4653\u001b[0m other_variable_or_arraylike: DaCompatible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(other, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m\"\u001b[39m, other)\n\u001b[1;32m   4654\u001b[0m other_coords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(other, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoords\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   4656\u001b[0m variable \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 4657\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_variable_or_arraylike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reflexive\n\u001b[1;32m   4659\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m f(other_variable_or_arraylike, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariable)\n\u001b[1;32m   4660\u001b[0m )\n\u001b[1;32m   4661\u001b[0m coords, indexes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoords\u001b[38;5;241m.\u001b[39m_merge_raw(other_coords, reflexive)\n\u001b[1;32m   4662\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_name(other)\n",
      "File \u001b[0;32m~/.local/miniforge/envs/emulator/lib/python3.11/site-packages/xarray/core/_typed_ops.py:476\u001b[0m, in \u001b[0;36mVariableOpsMixin.__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: VarCompatible) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self \u001b[38;5;241m|\u001b[39m T_DataArray:\n\u001b[0;32m--> 476\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_binary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/miniforge/envs/emulator/lib/python3.11/site-packages/xarray/core/variable.py:2414\u001b[0m, in \u001b[0;36mVariable._binary_op\u001b[0;34m(self, other, f, reflexive)\u001b[0m\n\u001b[1;32m   2411\u001b[0m attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs \u001b[38;5;28;01mif\u001b[39;00m keep_attrs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2412\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   2413\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 2414\u001b[0m         \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_data\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reflexive \u001b[38;5;28;01melse\u001b[39;00m f(other_data, self_data)\n\u001b[1;32m   2415\u001b[0m     )\n\u001b[1;32m   2416\u001b[0m result \u001b[38;5;241m=\u001b[39m Variable(dims, new_data, attrs\u001b[38;5;241m=\u001b[39mattrs)\n\u001b[1;32m   2417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (40140,3) (1,6) "
     ]
    }
   ],
   "source": [
    "# === NORMALIZE ============================================================= \n",
    "\n",
    "normalizer_dynamic = Normalizer(method=\"standardize\", type=\"spacetime\", axis_order=\"NTC\")\n",
    "\n",
    "normalizer_static = Normalizer(method=\"standardize\", type=\"space\", axis_order=\"NTC\")\n",
    "\n",
    "normalizer_target = Normalizer(method=\"standardize\", type=\"spacetime\", axis_order=\"NTC\")\n",
    "\n",
    "\n",
    "normalizer_dynamic.read_stats(f\"{dir_stats_output}/xd.npy\")\n",
    "normalizer_static.read_stats(f\"{dir_stats_output}/xs.npy\")\n",
    "normalizer_target.read_stats(f\"{dir_stats_output}/y.npy\")\n",
    "\n",
    "\n",
    "Xd_test = normalizer_dynamic.normalize(Xd_test)\n",
    "Xs = normalizer_static.normalize(Xs)\n",
    "Y_test = normalizer_target.normalize(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae7c727-0e48-4dac-ac8e-4edb240e1442",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==== MODEL ============================================================================\n",
    "\n",
    "model = CuDNNLSTM(\n",
    "                  hidden_size=HIDDEN_SIZE, \n",
    "                  dynamic_input_size=DYNAMIC_INPUT_SIZE,\n",
    "                  static_input_size=STATIC_INPUT_SIZE, \n",
    "                  output_size=OUTPUT_SIZE\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# model load precomputed weights \n",
    "print(f\"loading model {file_surr_model}\")\n",
    "model.load_state_dict(torch.load(file_surr_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d39e57-c88c-4cf9-a0cc-d73334d695f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PREDICT =============================================================================\n",
    "\n",
    "ds_target = xr.open_dataset(file_wflow_target, chunks= {\"time\":200}).isel(lat=slice(None, None, -1)).sel(layer=1, drop=True)\n",
    "\n",
    "lat, lon, time = len(masks.lat),len(masks.lon), Xd_test.shape[1]\n",
    "\n",
    "y_pred = predict(Xd_test.values, Xs.values, model, BATCH, device)\n",
    "\n",
    "\n",
    "y_pred = normalizer_target.denormalize(y_pred)\n",
    "\n",
    "Y_test = normalizer_target.denormalize( Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b4ee79-320e-408b-b3a5-1a07db6f074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EVALUATE ==============================================================================================\n",
    "\n",
    "for iv, var in enumerate(target_names):\n",
    "    print(var)\n",
    "    metrics_var = metrics.copy().pop(var)\n",
    "\n",
    "    y_target_plot, y_pred_plot = prepare_for_plotting(y_target= Y_test[:,:,[iv]].values,\n",
    "                                                y_pred = y_pred[:,:,[iv]], \n",
    "                                                shape = (lat, lon, time), \n",
    "                                                coords  = ds_target.sel(time=valid_temporal_range).coords)\n",
    "\n",
    "    y_target_plot= y_target_plot.where(~masks.values[...,None])\n",
    "    y_pred_plot = y_pred_plot.where(~masks.values[...,None])\n",
    "    \n",
    "    ts_compare(y_target_plot, y_pred_plot, lat = [46.4], lon = [11.4])    \n",
    "    \n",
    "    for metric in metrics_var:\n",
    "        print(metric)\n",
    "        if \"rmse\" in metric:\n",
    "            fig, ax, rmse = map_rmse(y_target_plot, y_pred_plot, unit = f\"{var} (mm)\", figsize = (8, 8), return_rmse=True, title=f\"{var} {metric}\")\n",
    "        elif \"kge\" in metric:\n",
    "            fig, ax, kge = map_kge(y_target_plot, y_pred_plot, figsize = (8, 8), return_kge =True, kwargs_imshow={\"vmin\":-0.5, \"vmax\":1},\n",
    "            ticks = np.linspace(-0.5, 1, 16), title=f\"{var} {metric}\")\n",
    "        elif \"pbias\" in metric:\n",
    "            fig, ax, pbias = map_pbias(y_target_plot, y_pred_plot, figsize = (8, 8), return_pbias=True, kwargs_imshow={\"vmin\":-100, \"vmax\":100}, \n",
    "                ticks = [l*10 for l in range(-10,11, 1)], title=f\"{var} {metric}\")\n",
    "        else:\n",
    "            print(f\"{metric} not found\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4639ec93-2a8b-4d88-8076-423e1b0783c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca76de3-910b-4fb3-a200-a3ec2f2ffbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emulator",
   "language": "python",
   "name": "emulator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
